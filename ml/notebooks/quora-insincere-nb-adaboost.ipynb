{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b545d117463d3c2d5da4a9a781d37bf82f457843"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f89fb1a64f63d3cb1845778718e695d2e5e3c2f"
   },
   "source": [
    "# Quora Insincere Questions Classification (Kaggle) - AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "165162c4c8adebaf5fc9b86e85a0eff988fa0c07"
   },
   "source": [
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-416e6107aed22920d238a91f3bae6681\" width=\"250px\" alt=\"Quora Logo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25d3103dfb31b81013fa4a3ca8b07f2614071896"
   },
   "source": [
    "## Table Of Contents:\n",
    "1. [Challenge Description](#Challenge-Description)\n",
    "2. [Data Files Description](#Data-Files-Description)\n",
    "3. [Import necessary libraries](#Import-necessary-libraries)\n",
    "4. [File Paths](#File-Paths)\n",
    "5. [Helper Methods](#Helper-Methods)\n",
    "6. [Data Wrangling](#Data-Wrangling)\n",
    "7. [Data Preprocessing](#Data-Preprocessing)\n",
    "8. [Vectorization](#Vectorization)\n",
    "8. [Machine Learning](#Machine-Learning)\n",
    "9. [Evaluation](#Evaluation)\n",
    "10. [Submission](#Submission)\n",
    "11. [Export the model](#Export-the-model)\n",
    "\n",
    "Model implementation inspired and modified from <a href=\"https://www.kaggle.com/adritab/sub1-no-deep-learning-vanilla-tfidf-logreg-svm?fbclid=IwAR2ob2La2qtWhWKwDwcc7CxCUHXa10_CiKMqJ4w7FK1i-KltVrhzYJPbuTo\"><i>here</i></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "febd1b97429e5997ce01b18f25d70947fb7887b6"
   },
   "source": [
    "### Challenge Description\n",
    "\n",
    "In this challenge, we have to train a model which is able to detect if a given question in insincere or not. The model should be able if the question is a statement rather than a question that if answered will provide benefit to Quora's online community. We will implement and compare various model and finally pick the highest performing one and deploy it on a live instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e72d87fff6af42c36b35a50af5703c1e15443b6"
   },
   "source": [
    "### Data Files Description\n",
    "\n",
    "Value to be predicted: *loyalty score* for each *card_id*\n",
    "\n",
    "Data files:\n",
    "* **train.csv**: Contains the training data\n",
    "* **test.csv**: Contains the testing data\n",
    "* **embeddings.zip**: A set of already existing embeddings for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "445677aec882614fdcf5e33c8c3bce80462a1122"
   },
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "0f031d4e082fa5e36862b1a8851ad739d231d0ae"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c51e71216669186f8fbab180cb0b07cb66ff505a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ac9e04e2eaf81cc8fe0f88dc109c9cfc991cbe8b"
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "255eacb1d2134623cf4b6bc7ecf91b5c42d6d19f"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "312d7606f10125925b1b3fc3b243e4acd72b9bed"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "47de3b76162ddc7a1785c4a925f208328c4e8915"
   },
   "outputs": [],
   "source": [
    "# Parameters and definitions\n",
    "RANDOM_SEED = 0\n",
    "VAL_SET_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6cf1e6fcc22e8b07d658afc9fdcfa860f9e2d1f3"
   },
   "outputs": [],
   "source": [
    "# Download essential resources\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "96e0dae0b6f3d3eb777e0fb4346da37ce9a4c959"
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbb4282c349d40ef1dd3e22eceaefb5028e44356"
   },
   "source": [
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c73b0d56a143137e5cdb3e4f0f7901ffc0987fb4"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/\"\n",
    "TRAIN_SAMPLES = DATA_DIR+\"train.csv\"\n",
    "TEST_SAMPLES = DATA_DIR+\"test.csv\"\n",
    "EMBD_SAMPLES = DATA_DIR+\"embeddings.zip\"\n",
    "MODEL_OUT = \"model-ada.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f467191eecaaee9b4d99c6cd9e44329448c3da37"
   },
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "d7670080c67178cbb698ce77a08ae11159a20198"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Loads the training and testing sets into the memory.\"\"\"\n",
    "    return pd.read_csv(TRAIN_SAMPLES), pd.read_csv(TEST_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a385d0a5a872f85110d62202d6656e86d5c9344a"
   },
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2b9e67b4a894ac2605c08e2aa084b38551256369"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "51d727217d293872bfee70562ca30abfb033052b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  ...   target\n",
       "0  00002165364db923c7e6  ...        0\n",
       "1  000032939017120e6e44  ...        0\n",
       "2  0000412ca6e4628ce2cf  ...        0\n",
       "3  000042bf85aa498cd78e  ...        0\n",
       "4  0000455dfa3e01eae3af  ...        0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sneak peak into the updated training set\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef4e3226766e635c4117b77b791bf564b32c6b7d"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "a803898fb3d4e07ba5c96c91dd3b686c6b24b15b"
   },
   "outputs": [],
   "source": [
    "def preprocess(data, col):\n",
    "    \"\"\"Preprocesses a given DataFrame. \n",
    "    \n",
    "    It applies conversion to lowercase, removes punctuation, removes digits, \n",
    "    removes stop words and stems the words.\n",
    "    \n",
    "    Args:\n",
    "        data: A pandas DataFrame.\n",
    "        col: The name of the column that needs NLP preprocessing.\n",
    "    \n",
    "    Returns:\n",
    "        The resulting data set.\n",
    "    \"\"\"\n",
    "    # Convert data set to lowercase\n",
    "    data[\"question_text\"] = data[\"question_text\"].apply(lambda s: s.lower())\n",
    "    \n",
    "    # Remove punctuation from the data set\n",
    "    data[\"question_text\"] = data['question_text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "    # Remove digits from the data set\n",
    "    data[\"question_text\"] = data[\"question_text\"].str.replace('\\d+', '')\n",
    "\n",
    "    # Remove stop words from question text\n",
    "    data[\"question_text\"] = data[\"question_text\"].apply(lambda s: \" \".join([item for item in s.split() if item not in stop_words]))\n",
    "\n",
    "    # Stem words\n",
    "    data[\"question_text\"] = data[\"question_text\"].apply(lambda s: \" \".join([stemmer.stem(w) for w in s.split()]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "816f907a9894252f3ef99eeeea84481d849612b5"
   },
   "outputs": [],
   "source": [
    "# Preprocess both data sets accordingly\n",
    "df_train = preprocess(df_train, \"question_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "65df3bd634b6ea93611bb5ec9d6f9ddff15234b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>quebec nationalist see provinc nation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>adopt dog would encourag peopl adopt shop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>veloc affect time veloc affect space geometri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>otto von guerick use magdeburg hemispher</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>convert montra helicon mountain bike chang tyre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  ...   target\n",
       "0  00002165364db923c7e6  ...        0\n",
       "1  000032939017120e6e44  ...        0\n",
       "2  0000412ca6e4628ce2cf  ...        0\n",
       "3  000042bf85aa498cd78e  ...        0\n",
       "4  0000455dfa3e01eae3af  ...        0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "60d05ab6559ee4dd8aa2516e735a5e32fad15bd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdfabe244dd371db2c9896a0532ed51cf4a95be9"
   },
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1853087c249841b5e5e408f7f0ab5666b8545715"
   },
   "outputs": [],
   "source": [
    "def build_TF(dt_train, dt_test):\n",
    "    \"\"\"Builds the TF-IDF matrix.\"\"\"\n",
    "    max_features = 50000  # More than this would filter in noise also\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range =(2,4) , max_df=0.90, min_df=5, max_features=max_features)\n",
    "    X = tfidf_vectorizer.fit_transform(dt_train['question_text'])\n",
    "    X_test = tfidf_vectorizer.transform(dt_test['question_text'])\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    y = dt_train[\"target\"]\n",
    "    return [train_test_split(X, y, test_size=VAL_SET_SIZE), X_test, tfidf_vectorizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "663185cc0695f147f21c9d93e378cfb5f15688ef"
   },
   "outputs": [],
   "source": [
    "tfvect = build_TF(df_train, df_test)\n",
    "X_train, X_val, y_train, y_val = tfvect[0]\n",
    "X_test = tfvect[1]\n",
    "tfidf_vectorizer = tfvect[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6ed09986aea4f0f6339a7f31b1112adad59c5810"
   },
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "64756a86ec97cf30419cc7e7e30e9c7b538846eb"
   },
   "outputs": [],
   "source": [
    "def build_model(X_train, y_train):\n",
    "    \"\"\"Builds an AdaBoost model.\"\"\"\n",
    "    return AdaBoostClassifier(random_state=RANDOM_SEED).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "c42e07cdd2b76339ec0e252be2f2613421a87836"
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "ada_model = build_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "74b5af6502e6f2a7b607834c39de9a3bf16b67f5"
   },
   "outputs": [],
   "source": [
    "# Produce predictions\n",
    "y_pred_train = ada_model.predict(X_train)\n",
    "y_pred_val = ada_model.predict(X_val)\n",
    "y_pred_test = ada_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0206329a656a868eee6efc9b9261c2b2b8e969c"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "23811f49929232e45c0de5092eeba5fad809e88e"
   },
   "outputs": [],
   "source": [
    "def produce_metrics(y, y_pred):\n",
    "    \"\"\"Produces a report containing the accuracy, f1-score, precision and recall metrics.\n",
    "    \n",
    "    Args:\n",
    "        y: The true classification\n",
    "        y_pred: The predicted classification\n",
    "    \"\"\"\n",
    "    print(\"Accuracy: {}, F1 Score: {}, Precision: {}, Recall: {}\".format(accuracy_score(y, y_pred),\n",
    "                                                                     f1_score(y, y_pred, average=\"macro\"),\n",
    "                                                                     precision_score(y, y_pred, average=\"macro\"),\n",
    "                                                                     recall_score(y, y_pred, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "4fa7a1b541a2745bb58cee18f376fd43b87672b2"
   },
   "outputs": [],
   "source": [
    "def produce_classification_report(y, y_pred):\n",
    "    \"\"\"Produces a classification report.\n",
    "    \n",
    "    Args:\n",
    "        y: The true classification\n",
    "        y_pred: The predicted classification\n",
    "    \"\"\"\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "2906068c31a8dbae33b69c7b1a2b2163af0f009e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9398715854289944, F1 Score: 0.5376517664246443, Precision: 0.806112808573314, Recall: 0.5279591022107871\n"
     ]
    }
   ],
   "source": [
    "produce_metrics(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "4c43f8883bab82d5331ea87556515de38ca3aefe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.940285194755479, F1 Score: 0.5390461908198274, Precision: 0.804229504915433, Recall: 0.5286986823703099\n"
     ]
    }
   ],
   "source": [
    "produce_metrics(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "b67f83e7cbec329dab2f973c735e9a75c3d5d4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    245149\n",
      "           1       0.67      0.06      0.11     16076\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    261225\n",
      "   macro avg       0.80      0.53      0.54    261225\n",
      "weighted avg       0.92      0.94      0.92    261225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "produce_classification_report(y_val, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26c61c23858a093ece42c30a28e7e1f037c25630"
   },
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "4c45baa37f61c83d7620eb44beb1eca5590214be"
   },
   "outputs": [],
   "source": [
    "def export_model(vectorizer, model):\n",
    "    \"\"\"Exports a model to a pickle file.\n",
    "    \n",
    "    Args:\n",
    "        model: A Scikit-learn model\n",
    "    \"\"\"\n",
    "    with open(MODEL_OUT, \"wb\") as f:\n",
    "        pickle.dump((vectorizer, model), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "abf7c70185e2b4b4c7f90921e54ab9434270d924"
   },
   "outputs": [],
   "source": [
    "export_model(tfidf_vectorizer, ada_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
